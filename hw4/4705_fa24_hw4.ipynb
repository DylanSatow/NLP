{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6703077a",
   "metadata": {},
   "source": [
    "# COMS W4705 Spring 24\n",
    "## Homework 4 - Semantic Role Labelling with BERT\n",
    "\n",
    "The goal of this assignment is to train and evaluate a PropBank-style semantic role labeling (SRL) system. Following (Collobert et al. 2011) and others, we will treat this problem as a sequence-labeling task. For each input token, the system will predict a B-I-O tag, as illustrated in the following example: \n",
    "\n",
    "|The|judge|scheduled|to|preside|over|his|trial|was|removed|from|the|case|today|.|             \n",
    "|---|-----|---------|--|-------|----|---|-----|---|-------|----|---|----|-----|-|             \n",
    "|B-ARG1|I-ARG1|B-V|B-ARG2|I-ARG2|I-ARG2|I-ARG2|I-ARG2|O|O|O|O|O|O|O|\n",
    "|||schedule.01|||||||||||||\n",
    "\n",
    "Note that the same sentence may have multiple annotations for different predicates\n",
    "\n",
    "|The|judge|scheduled|to|preside|over|his|trial|was|removed|from|the|case|today|.|             \n",
    "|---|-----|---------|--|-------|----|---|-----|---|-------|----|---|----|-----|-|             \n",
    "|B-ARG1|I-ARG1|I-ARG1|I-ARG1|I-ARG1|I-ARG1|I-ARG1|I-ARG1|O|B-V|B-ARG2|I-ARG2|I-ARG2|B-ARGM-TMP|O|\n",
    "||||||||||remove.01||||||\n",
    "\n",
    "and not all predicates need to be verbs\n",
    "\n",
    "|The|judge|scheduled|to|preside|over|his|trial|was|removed|from|the|case|today|.|             \n",
    "|---|-----|---------|--|-------|----|---|-----|---|-------|----|---|----|-----|-|    \n",
    "|O|O|O|O|O|O|B-ARG1|B-V|O|O|O|O|O|O|O|\n",
    "||||||||try.02||||||||\n",
    "\n",
    "The SRL system will be implemented in [PyTorch](https://pytorch.org/). We will use BERT (in the implementation provided by the [Huggingface transformers](https://huggingface.co/docs/transformers/index) library) to compute contextualized token representations and a custom classification head to predict semantic roles. We will fine-tune the pretrained BERT model on the SRL task. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff12fe94",
   "metadata": {},
   "source": [
    "### Overview of the Approach\n",
    "\n",
    "The model we will train is pretty straightforward. Essentially, we will just encode the sentence with BERT, then take the contextualized embedding for each token and feed it into a classifier to predict the corresponding tag. \n",
    "\n",
    "Because we are only working on argument identification and labeling (not predicate identification), it is essentially that we tell the model where the predicate is. This can be accomplished in various ways. The approach we will choose here repurposes Bert's *segment embeddings*. \n",
    "\n",
    "Recall that BERT is trained on two input sentences, seperated by [SEP], and on a next-sentence-prediction objective (in addition to the masked LM objective). To help BERT comprehend which sentence a given token belongs to, the original BERT uses a segment embedding, using A for the first sentene, and B for the second sentence 2. \n",
    "Because we are labeling only a single sentence at a time, we can use the segment embeddings to indicate the predicate position instead: The predicate is labeled as segment B (1) and all other tokens will be labeled as segment A (0). \n",
    "\n",
    "<img src=\"https://github.com/daniel-bauer/4705-f23-hw5/blob/main/bert_srl_model.png?raw=true\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68325e53",
   "metadata": {},
   "source": [
    "## Setup: GCP, Jupyter, PyTorch, GPU\n",
    "\n",
    "To make sure that PyTorch is available and can use the GPU,run the following cell which should return True. If it doesn't, make sure the GPU drivers and CUDA are installed correctly. \n",
    "\n",
    "GPU support is required for this assignment -- you will not be able to fine-tune BERT on a CPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad94eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe1c8ac",
   "metadata": {},
   "source": [
    "## Dataset: Ontonotes 5.0 English SRL annotations\n",
    "\n",
    "We will work with the English part of the [Ontonotes 5.0](https://catalog.ldc.upenn.edu/LDC2013T19) data. This is an extension of PropBank, using the same type of annotation. Ontonotes contains annotations other than predicate/argument structures, but we will use the PropBank style SRL annotations only. *Important*: This data set is provided to you for use in COMS 4705 only! Columbia is a subscriber to LDC and is allowed to use the data for educational purposes. However, you may not use the dataset in projects unrelated to Columbia teaching or research.\n",
    "\n",
    "If you haven't done so already, you can download the data here: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0c2f2645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-12-11 23:21:55--  https://storage.googleapis.com/4705-bert-srl-data/ontonotes_srl.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.68.59, 142.250.68.123, 142.250.72.187, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.68.59|:443... connected.\n",
      "HTTP request sent, awaiting response... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 OK\n",
      "Length: 12369688 (12M) [application/zip]\n",
      "Saving to: ‘ontonotes_srl.zip.3’\n",
      "\n",
      "ontonotes_srl.zip.3 100%[===================>]  11.80M  21.3MB/s    in 0.6s    \n",
      "\n",
      "2024-12-11 23:21:56 (21.3 MB/s) - ‘ontonotes_srl.zip.3’ saved [12369688/12369688]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://storage.googleapis.com/4705-bert-srl-data/ontonotes_srl.zip    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "14aad58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ontonotes_srl.zip\n",
      "replace propbank_dev.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! unzip ontonotes_srl.zip    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cae08a9",
   "metadata": {},
   "source": [
    "The data has been pre-processed in the following format. There are three files: \n",
    "\n",
    "`propbank_dev.tsv`\t`propbank_test.tsv`\t`propbank_train.tsv`\n",
    "\n",
    "Each of these files is in a tab-separated value format. A single predicate/argument structure annotation consists of four rows. For example \n",
    "\n",
    "```\n",
    "ontonotes/bc/cnn/00/cnn_0000.152.1\n",
    "The     judge   scheduled       to      preside over    his     trial   was     removed from    the     case    today   /.\n",
    "                schedule.01\n",
    "B-ARG1  I-ARG1  B-V     B-ARG2  I-ARG2  I-ARG2  I-ARG2  I-ARG2  O       O       O       O       O       O       O\n",
    "```\n",
    "\n",
    "* The first row is a unique identifier (1st annotation of the 152nd sentence in the file ontonotes/bc/cnn/00/cnn_0000).\n",
    "* The second row contains the tokens of the sentence (tab-separated). \n",
    "* The third row contains the probank frame name for the predicate (empty field for all other tokens). \n",
    "* The fourth row contains the B-I-O tag for each token. \n",
    "\n",
    "The file `rolelist.txt` contains a list of propbank BIO labels in the dataset (i.e. possible output tokens). This list has been filtered to contain only roles that appeared more than 1000 times in the training data. \n",
    "We will load this list and create mappings from numeric ids to BIO tags and back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "dc4c027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "role_to_id = {}\n",
    "with open(\"role_list.txt\",'r') as f:\n",
    "    role_list = [x.strip() for x in f.readlines()]\n",
    "    role_to_id = dict((role, index) for (index, role) in enumerate(role_list))\n",
    "    role_to_id['[PAD]'] = -100\n",
    "    \n",
    "    id_to_role = dict((index, role) for (role, index) in role_to_id.items())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07cdf31",
   "metadata": {},
   "source": [
    "Note that we are also mapping the '[PAD]' token to the value -100. This allows the loss function to ignore these tokens during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88096be5",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae727bf",
   "metadata": {},
   "source": [
    "## Part 1 - Data Preparation\n",
    "\n",
    "Before you can build the SRL model, you first need to preprocess the data. \n",
    "\n",
    "\n",
    "### 1.1 - Tokenization \n",
    "\n",
    "One challenge is that the pre-trained BERT model uses subword (\"WordPiece\") tokenization, but the Ontonotes data does not. Fortunately Huggingface transformers provides a tokenizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8a2d7d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " 'an',\n",
       " 'un',\n",
       " '##bel',\n",
       " '##ie',\n",
       " '##va',\n",
       " '##bly',\n",
       " 'boring',\n",
       " 'test',\n",
       " 'sentence',\n",
       " '.']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast \n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "tokenizer.tokenize(\"This is an unbelievably boring test sentence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1924bd",
   "metadata": {},
   "source": [
    "**TODO**: \n",
    "We need to be able to maintain the correct labels (B-I-O tags) for each of the subwords. \n",
    "Complete the following function that takes a list of tokens and a list of B-I-O labels of the same length as parameters, and returns a new token / label pair, as illustrated in the following example. \n",
    "\n",
    "\n",
    "```\n",
    ">>> tokenize_with_labels(\"the fancyful penguin devoured yummy fish .\".split(), \"B-ARG0 I-ARG0 I-ARG0 B-V B-ARG1 I-ARG1 O\".split(), tokenizer)\n",
    "(['the',\n",
    "  'fancy',\n",
    "  '##ful',\n",
    "  'penguin',\n",
    "  'dev',\n",
    "  '##oured',\n",
    "  'yu',\n",
    "  '##mmy',\n",
    "  'fish',\n",
    "  '.'],\n",
    " ['B-ARG0',\n",
    "  'I-ARG0',\n",
    "  'I-ARG0',\n",
    "  'I-ARG0',\n",
    "  'B-V',\n",
    "  'I-V',\n",
    "  'B-ARG1',\n",
    "  'I-ARG1',\n",
    "  'I-ARG1',\n",
    "  'O'])\n",
    "\n",
    "```\n",
    "\n",
    "To approach this problem, iterate through each word/label pair in the sentence. Call the tokenizer on the word. This may result in one or more tokens. Create the correct number of labels to match the number of tokens. Take care to not generate multiple B- tokens. \n",
    "\n",
    "\n",
    "This approach is a bit slower than tokenizing the entire sentence, but is necessary to produce proper input tokenization for the pre-trained BERT model, and the matching target labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8140fc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_with_labels(sentence, text_labels, tokenizer):\n",
    "    \"\"\"\n",
    "    Word piece tokenization makes it difficult to match word labels\n",
    "    back up with individual word pieces. \n",
    "    \"\"\"\n",
    "\n",
    "    tokenized_sentence = []\n",
    "    labels = []\n",
    "    \n",
    "    for word, label in zip(sentence, text_labels):\n",
    "        w_toks = tokenizer.tokenize(word)\n",
    "        tokenized_sentence.append(w_toks[0])\n",
    "        labels.append(label)\n",
    "        for tok in w_toks[1:]:\n",
    "            tokenized_sentence.append(f'##{tok}')\n",
    "            if label != 'O':\n",
    "                labels.append(f'I-{label[2:]}')\n",
    "            else:\n",
    "                labels.append('O')\n",
    "\n",
    "    return tokenized_sentence, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f748d120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['the',\n",
       "  'fancy',\n",
       "  '####ful',\n",
       "  'penguin',\n",
       "  'dev',\n",
       "  '####oured',\n",
       "  'yu',\n",
       "  '####mmy',\n",
       "  'fish',\n",
       "  '.'],\n",
       " ['B-ARG0',\n",
       "  'I-ARG0',\n",
       "  'I-ARG0',\n",
       "  'I-ARG0',\n",
       "  'B-V',\n",
       "  'I-V',\n",
       "  'B-ARG1',\n",
       "  'I-ARG1',\n",
       "  'I-ARG1',\n",
       "  'O'])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_with_labels(\"the fancyful penguin devoured yummy fish .\".split(), \"B-ARG0 I-ARG0 I-ARG0 B-V B-ARG1 I-ARG1 O\".split(), tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bb9076",
   "metadata": {},
   "source": [
    "### 1.2 Loading the Dataset\n",
    "\n",
    "Next, we are creating a PyTorch [Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) class. This class acts as a contained for the training, development, and testing data in memory. You should already be familiar with Datasets and Dataloaders from homework 3. \n",
    "\n",
    "1.2.1 **TODO**: Write the \\_\\_init\\_\\_(self, filename) method that reads in the data from a data file (specified by the filename).\n",
    "\n",
    "For each annotation you start with  the tokens in the sentence, and the BIO tags. Then you need to create the following \n",
    "\n",
    "1. call the `tokenize_with_labels` function to tokenize the sentence.\n",
    "2. Add the (token, label) pair to the self.items list. \n",
    "\n",
    "1.2.2 **TODO**: Write the \\_\\_len\\_\\_(self) method that returns the total number of items. \n",
    "\n",
    "1.2.3 **TODO**: Write the \\_\\_getitem\\_\\_(self, k) method that returns a single item in a format BERT will understand. \n",
    "* We need to process the sentence by adding \"\\[CLS\\]\" as the first token and \"\\[SEP\\]\" as the last token. The need to pad the token sequence to 128 tokens using the \"\\[PAD\\]\" symbol. This needs to happen both for the inputs (sentence token sequence) and outputs (BIO tag sequence).\n",
    "* We need to create an *attention mask*, which is a sequence of 128 tokens indicating the actual input symbols (as a 1) and \\[PAD\\] symbols (as a 0).\n",
    "* We need to create a *predicate indicator* mask, which is a sequence of 128 tokens with at most one 1, in the position of the \"B-V\" tag. All other entries should be 0. The model will use this information to understand where the predicate is located. \n",
    "\n",
    "* Finally, we need to convert the token and tag sequence into numeric indices. For the tokens, this can be done using the `tokenizer.convert_tokens_to_ids` method. For the tags, use the `role_to_id` dictionary. \n",
    "Each sequence must be a pytorch tensor of shape (1,128). You can convert a list of integer values like this `torch.tensor(token_ids, dtype=torch.long)`.\n",
    "\n",
    "To keep everything organized, we will return a dictionary in the following format \n",
    "\n",
    "```\n",
    "{'ids': token_tensor,\n",
    " 'targets': tag_tensor,\n",
    " 'mask': attention_mask_tensor,\n",
    " 'pred': predicate_indicator_tensor}\n",
    "```\n",
    "\n",
    "\n",
    "(Hint: To debug these, read in the first annotation only / the first few annotations) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "9f5bd32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader \n",
    "import torch\n",
    "\n",
    "def load_SRL_data(filename):\n",
    "    with open(filename,'r') as prop_list_f: \n",
    "        return [line.strip() for line in prop_list_f] \n",
    "   \n",
    "\n",
    "class SrlData(Dataset):\n",
    "    \n",
    "    def __init__(self, filename):\n",
    "\n",
    "        super(SrlData, self).__init__()\n",
    "        \n",
    "        self.max_len = 128 # the max number of tokens inputted to the transformer. \n",
    "        \n",
    "        self.tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased', do_lower_case=True)        \n",
    "        \n",
    "        self.items = []\n",
    "        \n",
    "        data = load_SRL_data(filename)\n",
    "        for s,props in zip(data[1::4],data[3::4]):\n",
    "            toks_labels = tokenize_with_labels(s.split(), props.split(), self.tokenizer)\n",
    "            self.items.append(toks_labels)\n",
    "                                                        \n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "    def __getitem__(self, k):\n",
    "        toks,labels = self.items[k]\n",
    "        s_len = len(toks)\n",
    "\n",
    "        if s_len > self.max_len - 2:  # -2 for [CLS] and [SEP]\n",
    "            toks = toks[:(self.max_len - 2)]\n",
    "            labels = labels[:(self.max_len - 2)]\n",
    "            s_len = self.max_len - 2\n",
    "        \n",
    "        toks = ['[CLS]'] + toks + ['[SEP]'] + (['[PAD]'] * (128 - (s_len + 2)))\n",
    "        toks = self.tokenizer.convert_tokens_to_ids(toks)\n",
    "        toks = torch.tensor(toks,dtype=torch.long).unsqueeze(0)\n",
    "        \n",
    "        labels = ['[CLS]'] + labels + ['[SEP]'] + (['[PAD]'] * (128 - (s_len + 2)))\n",
    "        tags = []\n",
    "        for l in labels:\n",
    "            if l not in role_to_id:\n",
    "                tags.append(role_to_id['O'])\n",
    "            else:\n",
    "                tags.append(role_to_id[l])\n",
    "        tags = torch.tensor(tags,dtype=torch.long).unsqueeze(0)\n",
    "        \n",
    "        mask = ([1] * (s_len + 2)) + ([0] * (128 - (s_len + 2)))\n",
    "        mask = torch.tensor(mask,dtype=torch.long).unsqueeze(0)\n",
    "        \n",
    "        pred_mask = [0] * 128\n",
    "        if 'B-V' in labels:\n",
    "            pred_mask[labels.index('B-V')] = 1\n",
    "        pred_mask = torch.tensor(pred_mask,dtype=torch.long)\n",
    "        \n",
    "        return {'ids': toks,\n",
    "                'mask':  mask,\n",
    "                'targets': tags,\n",
    "                'pred': pred_mask\n",
    "               }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "da0b476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the training data takes a while for the entire data because we preprocess all data offline\n",
    "data = SrlData(\"propbank_train.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0730aff9",
   "metadata": {},
   "source": [
    "## 2. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "cb11f9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module, Linear, CrossEntropyLoss\n",
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da684eff",
   "metadata": {},
   "source": [
    "We will define the pyTorch model as a subclass of the [torch.nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) class. The code for the model is provided for you. It may help to take a look at the documentation to remind you of how Module works. Take a look at how the huggingface BERT model simply becomes another sub-module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "37515695",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SrlModel(Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(SrlModel, self).__init__()\n",
    "        \n",
    "        self.encoder = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "    \n",
    "        # The following two lines would freeze the BERT parameters and allow us to train the classifier by itself.\n",
    "        # We are fine-tuning the model, so you can leave this commented out!\n",
    "        # for param in self.encoder.parameters():\n",
    "        #    param.requires_grad = False\n",
    "        \n",
    "        # The linear classifier head, see model figure in the introduction. \n",
    "        self.classifier = Linear(768, len(role_to_id))\n",
    "                \n",
    "        \n",
    "    def forward(self, input_ids, attn_mask, pred_indicator):\n",
    "    \n",
    "        # This defines the flow of data through the model \n",
    "    \n",
    "        # Note the use of the \"token type ids\" which represents the segment encoding explained in the introduction. \n",
    "        # In our segment encoding, 1 indicates the predicate, and 0 indicates everything else. \n",
    "        bert_output =  self.encoder(input_ids=input_ids, attention_mask=attn_mask, token_type_ids=pred_indicator)\n",
    "\n",
    "        enc_tokens = bert_output[0] # the result of encoding the input with BERT\n",
    "        logits = self.classifier(enc_tokens) #feed into the classification layer to produce scores for each tag.\n",
    "        \n",
    "        # Note that we are only interested in the argmax for each token, so we do not have to normalize \n",
    "        # to a probability distribution using softmax. The CrossEntropyLoss loss function takes this into account.\n",
    "        # It essentially computes the softmax first and then computes the negative log-likelihood for the target classes. \n",
    "        return logits        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ba23ec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SrlModel().to('cuda') # create new model and store weights in GPU memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9103d32e",
   "metadata": {},
   "source": [
    "Now we are ready to try running the model with just a single input example to check if it is working correctly. Clearly it has not been trained, so the output is not what we expect. But we can see what the loss looks like for an initial sanity check. \n",
    "\n",
    "**TODO**: \n",
    "* Take a single data item from the dev set, as provided by your Dataset class defined above. Obtain the input token ids, attention mask, predicate indicator mask, and target labels. \n",
    "* Run the model on the ids, attention mask, and predicate mask like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "f1805480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick an item from the dataset. Then run \n",
    "dev_data = SrlData(\"propbank_dev.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "86b042dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids: torch.Size([1, 128]), mask: torch.Size([1, 128]), pred: torch.Size([128]), targs: torch.Size([1, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 53])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = 10\n",
    "data_dict = dev_data[ix]\n",
    "\n",
    "ids = data_dict['ids'].to('cuda')\n",
    "mask = data_dict['mask'].to('cuda')\n",
    "pred = data_dict['pred'].to('cuda')\n",
    "targets = data_dict['targets'].to('cuda')\n",
    "print(f'ids: {ids.shape}, mask: {mask.shape}, pred: {pred.shape}, targs: {targets.shape}')\n",
    "\n",
    "outputs = model(ids, mask, pred)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7fd38b",
   "metadata": {},
   "source": [
    "**TODO**: \n",
    "Compute the loss on this one item only.\n",
    "The initial loss should be close to -ln(1/num_labels)\n",
    "\n",
    "Without training we would assume that all labels for each token (including the target label) are equally likely, so the negative log probability for the targets should be approximately $$-\\ln(\\frac{1}{\\text{num_labels}}).$$ This is what the loss function should return on a single example. This is a good sanity check to run for any multi-class prediction problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "1a5f881d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.970291913552122"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "-math.log(1 / len(role_to_id), math.e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "1a124d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.078204154968262\n"
     ]
    }
   ],
   "source": [
    "loss_function = CrossEntropyLoss(ignore_index = -100, reduction='mean')\n",
    "\n",
    "# Transpose outputs to get shape [1, 53, 128]\n",
    "outputs = outputs.transpose(1, 2)\n",
    "\n",
    "# Now targets is [1, 128] which is correct\n",
    "loss = loss_function(outputs, targets)\n",
    "print(f\"Loss: {loss.item()}\")\n",
    "\n",
    "# complete this. Note that you still have to provide a (batch_size, input_pos) \n",
    "# tensor for each parameter, where batch_size =1\n",
    "\n",
    "# outputs = model(ids, mask, pred) \n",
    "# loss = loss_function(...)\n",
    "# loss.item()   #this should be approximately the score from the previous cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669a1037",
   "metadata": {},
   "source": [
    "**TODO**: At this point you should also obtain the actual predictions by taking the argmax over each position.\n",
    "The result should look something like this (values will differ).\n",
    "\n",
    "```\n",
    "tensor([[ 1,  4,  4,  4,  4,  4,  5, 29, 29, 29,  4, 28,  6, 32, 32, 32, 32, 32,\n",
    "         32, 32, 30, 30, 32, 30, 32,  4, 32, 32, 30,  4, 49,  4, 49, 32, 30,  4,\n",
    "         32,  4, 32, 32,  4,  2,  4,  4, 32,  4, 32, 32, 32, 32, 30, 32, 32, 30,\n",
    "         32,  4,  4, 49,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  6,  6, 32, 32,\n",
    "         30, 32, 32, 32, 32, 32, 30, 30, 30, 32, 30, 49, 49, 32, 32, 30,  4,  4,\n",
    "          4,  4, 29,  4,  4,  4,  4,  4,  4, 32,  4,  4,  4, 32,  4, 30,  4, 32,\n",
    "         30,  4, 32,  4,  4,  4,  4,  4, 32,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
    "          4,  4]], device='cuda:0')\n",
    "```\n",
    "\n",
    "Then use the id_to_role dictionary to decode to actual tokens. \n",
    "\n",
    "```\n",
    "['[CLS]', 'O', 'O', 'O', 'O', 'O', 'B-ARG0', 'I-ARG0', 'I-ARG0', 'I-ARG0', 'O', 'B-V', 'B-ARG1', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG1', 'I-ARG1', 'I-ARG2', 'I-ARG1', 'I-ARG2', 'O', 'I-ARG2', 'I-ARG2', 'I-ARG1', 'O', 'I-ARGM-TMP', 'O', 'I-ARGM-TMP', 'I-ARG2', 'I-ARG1', 'O', 'I-ARG2', 'O', 'I-ARG2', 'I-ARG2', 'O', '[SEP]', 'O', 'O', 'I-ARG2', 'O', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG1', 'I-ARG2', 'I-ARG2', 'I-ARG1', 'I-ARG2', 'O', 'O', 'I-ARGM-TMP', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ARG1', 'B-ARG1', 'I-ARG2', 'I-ARG2', 'I-ARG1', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG2', 'I-ARG1', 'I-ARGM-TMP', 'I-ARGM-TMP', 'I-ARG2', 'I-ARG2', 'I-ARG1', 'O', 'O', 'O', 'O', 'I-ARG0', 'O', 'O', 'O', 'O', 'O', 'O', 'I-ARG2', 'O', 'O', 'O', 'I-ARG2', 'O', 'I-ARG1', 'O', 'I-ARG2', 'I-ARG1', 'O', 'I-ARG2', 'O', 'O', 'O', 'O', 'O', 'I-ARG2', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "```\n",
    "\n",
    "For now, just make sure you understand how to do this for a single example. Later, you will write a more formal function to do this once we have trained the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "69c2dcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ARGM-ADV', 'I-ARGM-LVB', 'B-ARGM-DIS', 'B-ARGM-DIS', 'B-ARGM-DIS', 'B-ARGM-DIS', 'B-ARG4', 'B-ARGM-DIS', 'B-ARGM-DIS', 'O', 'B-ARG4', 'B-ARGM-DIS', 'B-ARGM-DIS', 'I-ARG1', 'B-ARGM-MNR', 'B-ARGM-MNR', 'I-ARG2', 'I-ARG2', 'I-ARG1', 'I-ARG2', 'I-ARG2', 'I-ARG1', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG1', 'O', 'I-ARG1', 'I-ARGM-GOL', 'I-ARGM-ADV', 'I-ARG2', 'I-ARGM-NEG', 'B-ARG4', 'I-ARG2', 'I-ARGM-NEG', 'I-ARG2', 'I-ARG2', 'I-ARGM-NEG', 'I-ARG2', 'I-ARG2', 'I-ARGM-NEG', 'I-ARG1', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG1', 'B-ARGM-DIS', 'O', 'I-ARG1', 'I-ARGM-GOL', 'I-ARGM-ADV', 'I-ARG2', 'B-ARG4', 'I-ARGM-ADV', 'I-ARG2', 'I-ARGM-NEG', 'B-ARG4', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'B-ARG4', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG1', 'B-ARGM-DIS', 'I-ARG2', 'I-ARGM-PRP', 'I-ARGM-ADV', 'I-ARGM-NEG', 'B-ARG4', 'B-ARG3', 'B-ARGM-DIS', 'I-ARGM-NEG', 'I-ARGM-NEG', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARGM-NEG', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'B-ARGM-DIS', 'I-ARG1', 'I-ARG1', 'I-ARG2', 'I-ARG2', 'I-ARG1', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'B-ARG4', 'I-ARG2', 'I-ARG2', 'I-ARG2']\n"
     ]
    }
   ],
   "source": [
    "# Get predictions by taking argmax along the class dimension\n",
    "predictions = torch.argmax(outputs, dim=1)  # Shape will be [1, 128]\n",
    "\n",
    "tok_preds = []\n",
    "for ix, n in enumerate(predictions.to('cpu').tolist()[0]):\n",
    "    if n not in id_to_role:\n",
    "        tok_preds.append('O')\n",
    "    else:\n",
    "        tok_preds.append(id_to_role[n])\n",
    "\n",
    "print(tok_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d52991",
   "metadata": {},
   "source": [
    "## 3. Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edba250d",
   "metadata": {},
   "source": [
    "pytorch provides a DataLoader class that can be wrapped around a Dataset to easily use the dataset for training. The DataLoader allows us to easily adjust the batch size and shuffle the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "2ecd7448",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "loader = DataLoader(data, batch_size = 32, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7496c62",
   "metadata": {},
   "source": [
    "The following cell contains the main training loop. The code should work as written and report the loss after each batch,\n",
    "cumulative average loss after each 100 batches, and print out the final average loss after the epoch. \n",
    "\n",
    "**TODO**: Modify the training loop belowso that it also computes the accuracy for each batch and reports the \n",
    "average accuracy after the epoch. \n",
    "The accuracy is the number of correctly predicted token labels out of the number of total predictions. \n",
    "Make sure you exclude [PAD] tokens, i.e. tokens for which the target label is -100. It's okay to include [CLS] and [SEP] in the accuracy calculation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "7a7abad9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_function = CrossEntropyLoss(ignore_index = -100, reduction='mean')\n",
    "\n",
    "LEARNING_RATE = 1e-05\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "def train():\n",
    "    \"\"\"\n",
    "    Train the model for one epoch.\n",
    "    \"\"\"\n",
    "    tr_loss = 0 \n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    total_correct = 0\n",
    "    total_predictions = 0\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    for idx, batch in enumerate(loader):\n",
    "        \n",
    "        # Get the encoded data for this batch and push it to the GPU\n",
    "        ids = batch['ids'].squeeze(1).to(device, dtype = torch.long)\n",
    "        mask = batch['mask'].squeeze(1).to(device, dtype = torch.long)\n",
    "        targets = batch['targets'].squeeze(1).to(device, dtype = torch.long)\n",
    "        pred_mask = batch['pred'].squeeze(1).to(device, dtype = torch.long)\n",
    "\n",
    "        # Run the forward pass of the model\n",
    "        logits = model(input_ids=ids, attn_mask=mask, pred_indicator=pred_mask)        \n",
    "        loss = loss_function(logits.transpose(2,1), targets) \n",
    "        tr_loss += loss.item()\n",
    "        # print(\"Batch loss: \", loss.item()) # can comment out if too verbose.\n",
    "        \n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += targets.size(0)\n",
    "        \n",
    "        if idx % 100==0:\n",
    "            #torch.cuda.empty_cache() # can help if you run into memory issues\n",
    "            curr_avg_loss = tr_loss/nb_tr_steps\n",
    "            print(f\"Current average loss: {curr_avg_loss}\")\n",
    "                   \n",
    "        # Compute accuracy for this batch\n",
    "        matching = torch.sum(torch.argmax(logits,dim=2) == targets)       \n",
    "        predictions = torch.sum(torch.where(targets==-100,0,1))\n",
    "\n",
    "        total_correct += matching.item()\n",
    "        total_predictions += predictions.item()\n",
    "                \n",
    "        # Run the backward pass to update parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    epoch_accuracy = total_correct / total_predictions if total_predictions > 0 else 0\n",
    "\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {epoch_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890d12b0",
   "metadata": {},
   "source": [
    "Now let's train the model for one epoch. This will take a while (up to a few hours). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "bef88882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current average loss: 1.199844241142273\n",
      "Current average loss: 1.0573418429582426\n",
      "Current average loss: 0.9984575824357977\n",
      "Current average loss: 0.9563420975327096\n",
      "Current average loss: 0.9265619123963049\n",
      "Current average loss: 0.8936250694021731\n",
      "Current average loss: 0.8631760304462096\n",
      "Current average loss: 0.8368185120455378\n",
      "Current average loss: 0.8148368098092883\n",
      "Current average loss: 0.793070558768663\n",
      "Current average loss: 0.7743656497139793\n",
      "Current average loss: 0.7555619941636933\n",
      "Current average loss: 0.7388871813147987\n",
      "Current average loss: 0.7228814854152746\n",
      "Current average loss: 0.7079119443638167\n",
      "Current average loss: 0.6930224598645369\n",
      "Current average loss: 0.6795355472097093\n",
      "Current average loss: 0.6674891628197962\n",
      "Current average loss: 0.6560261631627535\n",
      "Current average loss: 0.6455117541667601\n",
      "Current average loss: 0.6346194347043683\n",
      "Current average loss: 0.6247922250099377\n",
      "Current average loss: 0.6150932489864288\n",
      "Current average loss: 0.6065080439148132\n",
      "Current average loss: 0.5978483627831523\n",
      "Current average loss: 0.5902446928809806\n",
      "Current average loss: 0.5821821102611104\n",
      "Current average loss: 0.5746118938677931\n",
      "Current average loss: 0.567470894742761\n",
      "Current average loss: 0.560330913354306\n",
      "Current average loss: 0.5537006989622942\n",
      "Current average loss: 0.5469639782740662\n",
      "Current average loss: 0.5408876267113711\n",
      "Current average loss: 0.5348845727829744\n",
      "Current average loss: 0.5297562198248446\n",
      "Current average loss: 0.52421455428332\n",
      "Current average loss: 0.5193082606319056\n",
      "Current average loss: 0.5145222861435536\n",
      "Current average loss: 0.509932399029341\n",
      "Current average loss: 0.5056198073641303\n",
      "Current average loss: 0.5013809920500678\n",
      "Current average loss: 0.49711528701139523\n",
      "Current average loss: 0.492934089060895\n",
      "Current average loss: 0.4885260857671146\n",
      "Current average loss: 0.48471603809879793\n",
      "Current average loss: 0.48092469341276595\n",
      "Current average loss: 0.4771721717605796\n",
      "Current average loss: 0.47335210278031165\n",
      "Current average loss: 0.46967027100317926\n",
      "Current average loss: 0.4665636661477878\n",
      "Current average loss: 0.46308173811619247\n",
      "Current average loss: 0.46002763787558726\n",
      "Current average loss: 0.456923039086769\n",
      "Current average loss: 0.4538676074764522\n",
      "Current average loss: 0.4509125047288676\n",
      "Current average loss: 0.44790139440172827\n",
      "Current average loss: 0.4452567907744296\n",
      "Current average loss: 0.44230794480177965\n",
      "Current average loss: 0.43936266422841985\n",
      "Current average loss: 0.4367792481495614\n",
      "Current average loss: 0.43419715516186025\n",
      "Current average loss: 0.43180244375576526\n",
      "Current average loss: 0.4292465365907681\n",
      "Current average loss: 0.4270383357680084\n",
      "Current average loss: 0.4247205959662965\n",
      "Current average loss: 0.422638041851906\n",
      "Current average loss: 0.42044883366652175\n",
      "Current average loss: 0.41830099578971847\n",
      "Current average loss: 0.4161018155139433\n",
      "Current average loss: 0.4139921268252009\n",
      "Current average loss: 0.4122839785251357\n",
      "Current average loss: 0.41022347316718777\n",
      "Current average loss: 0.40852745648780275\n",
      "Current average loss: 0.4067646798561279\n",
      "Current average loss: 0.4047982194865496\n",
      "Current average loss: 0.4030102016482492\n",
      "Current average loss: 0.4012322201942585\n",
      "Current average loss: 0.3994448012339188\n",
      "Current average loss: 0.3976265993754828\n",
      "Current average loss: 0.39586595825425674\n",
      "Current average loss: 0.39414813983084307\n",
      "Current average loss: 0.3923887572846888\n",
      "Current average loss: 0.390704302013887\n",
      "Current average loss: 0.38900784594623344\n",
      "Current average loss: 0.3873405093219632\n",
      "Current average loss: 0.38571680870852376\n",
      "Current average loss: 0.38402324198980053\n",
      "Current average loss: 0.3825600657656184\n",
      "Current average loss: 0.3812154549603746\n",
      "Current average loss: 0.3799322651532403\n",
      "Current average loss: 0.37856922819655864\n",
      "Current average loss: 0.377167459317399\n",
      "Current average loss: 0.3757809832426546\n",
      "Current average loss: 0.37450386440416855\n",
      "Current average loss: 0.37300296543240735\n",
      "Current average loss: 0.3716514055460218\n",
      "Current average loss: 0.37028759052503013\n",
      "Current average loss: 0.3691255867530385\n",
      "Current average loss: 0.36799582191029806\n",
      "Training loss epoch: 0.36774925010483334\n",
      "Training accuracy epoch: 0.8947040542096628\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8507d02",
   "metadata": {},
   "source": [
    "In my experiments, I found that two epochs are needed for good performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "0070c530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current average loss: 0.20046962797641754\n",
      "Current average loss: 0.21293375456687247\n",
      "Current average loss: 0.21131860550066725\n",
      "Current average loss: 0.2134070033052831\n",
      "Current average loss: 0.21675453045198745\n",
      "Current average loss: 0.21910934199294643\n",
      "Current average loss: 0.22131952986790615\n",
      "Current average loss: 0.21978585602723583\n",
      "Current average loss: 0.21823122545834933\n",
      "Current average loss: 0.21760978063487849\n",
      "Current average loss: 0.2173287448111352\n",
      "Current average loss: 0.21729202023779232\n",
      "Current average loss: 0.21656204972859724\n",
      "Current average loss: 0.2162424916606239\n",
      "Current average loss: 0.2164528869507272\n",
      "Current average loss: 0.21538340291138652\n",
      "Current average loss: 0.21469378297093286\n",
      "Current average loss: 0.2141739760297211\n",
      "Current average loss: 0.21340179423915884\n",
      "Current average loss: 0.21376472136602473\n",
      "Current average loss: 0.2133763051558768\n",
      "Current average loss: 0.2132294177920378\n",
      "Current average loss: 0.21317673801719086\n",
      "Current average loss: 0.21289104323790467\n",
      "Current average loss: 0.21286398609452375\n",
      "Current average loss: 0.21232886768665996\n",
      "Current average loss: 0.21228286437332194\n",
      "Current average loss: 0.21191872513871288\n",
      "Current average loss: 0.21149057130336293\n",
      "Current average loss: 0.21110996237600602\n",
      "Current average loss: 0.21114732874126008\n",
      "Current average loss: 0.2114852995235414\n",
      "Current average loss: 0.21122659263700033\n",
      "Current average loss: 0.21115812865221043\n",
      "Current average loss: 0.2108087015667669\n",
      "Current average loss: 0.21099391437575363\n",
      "Current average loss: 0.21016398782644527\n",
      "Current average loss: 0.2100193126268546\n",
      "Current average loss: 0.2099110716118354\n",
      "Current average loss: 0.2098681145982463\n",
      "Current average loss: 0.20980823926685363\n",
      "Current average loss: 0.2100658770609748\n",
      "Current average loss: 0.20986296513628402\n",
      "Current average loss: 0.20952077360225677\n",
      "Current average loss: 0.20955252242705222\n",
      "Current average loss: 0.20940837287152642\n",
      "Current average loss: 0.20933047001195637\n",
      "Current average loss: 0.20914369791514745\n",
      "Current average loss: 0.20884681741500044\n",
      "Current average loss: 0.20876523983695025\n",
      "Current average loss: 0.20857749047594723\n",
      "Current average loss: 0.20836561673825288\n",
      "Current average loss: 0.20839940070736365\n",
      "Current average loss: 0.20838887081775795\n",
      "Current average loss: 0.2079252892368161\n",
      "Current average loss: 0.2077264135428839\n",
      "Current average loss: 0.2074357490421906\n",
      "Current average loss: 0.20720383229406858\n",
      "Current average loss: 0.20670638106271452\n",
      "Current average loss: 0.20635555656852508\n",
      "Current average loss: 0.20604271358886256\n",
      "Current average loss: 0.20611837859467158\n",
      "Current average loss: 0.2060436223641247\n",
      "Current average loss: 0.20596651737887867\n",
      "Current average loss: 0.20595512160042861\n",
      "Current average loss: 0.20581178035351555\n",
      "Current average loss: 0.20549956771451006\n",
      "Current average loss: 0.20530373099543694\n",
      "Current average loss: 0.20514740865995842\n",
      "Current average loss: 0.20472788241868814\n",
      "Current average loss: 0.20460014579794505\n",
      "Current average loss: 0.20448269478692385\n",
      "Current average loss: 0.20446631967413012\n",
      "Current average loss: 0.2043839974764879\n",
      "Current average loss: 0.20421337994985075\n",
      "Current average loss: 0.20420191180144226\n",
      "Current average loss: 0.2039329693718241\n",
      "Current average loss: 0.20396124211610053\n",
      "Current average loss: 0.20366868261978988\n",
      "Current average loss: 0.2036055287431349\n",
      "Current average loss: 0.20351295376729853\n",
      "Current average loss: 0.20342543239730213\n",
      "Current average loss: 0.2032248629253676\n",
      "Current average loss: 0.2030462163131706\n",
      "Current average loss: 0.202852733851405\n",
      "Current average loss: 0.20275705613291428\n",
      "Current average loss: 0.2027002079205525\n",
      "Current average loss: 0.2024860545901228\n",
      "Current average loss: 0.20248606499699745\n",
      "Current average loss: 0.20226461583920682\n",
      "Current average loss: 0.2021375394399074\n",
      "Current average loss: 0.20207018394883997\n",
      "Current average loss: 0.20196008564755133\n",
      "Current average loss: 0.2018427433919271\n",
      "Current average loss: 0.20174394004065146\n",
      "Current average loss: 0.20144142973185866\n",
      "Current average loss: 0.20123983545035026\n",
      "Current average loss: 0.20109320347042886\n",
      "Current average loss: 0.2008865013632704\n",
      "Training loss epoch: 0.20087222307563787\n",
      "Training accuracy epoch: 0.9375332174517713\n"
     ]
    }
   ],
   "source": [
    "train() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4005af14",
   "metadata": {},
   "source": [
    "I ended up with a training loss of about 0.19 and a training accuracy of 0.94. Specific values may differ. \n",
    "\n",
    "At this point, it's a good idea to save the model (or rather the parameter dictionary) so you can continue evaluating the model without having to retrain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "542403f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"srl_model_fulltrain_2epoch_finetune_1e-05.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dc1647",
   "metadata": {},
   "source": [
    "## 4. Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d7b2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10969/3484726954.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"srl_model_fulltrain_2epoch_finetune_1e-05.pt\"))\n"
     ]
    }
   ],
   "source": [
    "# Optional step: If you stopped working after part 3, first load the trained model \n",
    "\n",
    "model = SrlModel().to('cuda') \n",
    "model.load_state_dict(torch.load(\"srl_model_fulltrain_2epoch_finetune_1e-05.pt\"))\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e07781",
   "metadata": {},
   "source": [
    "**TODO (this is the fun part)**: Now that we have a trained model, let's try labeling an unseen example sentence. Complete the functions decode_output and label_sentence below. decode_output takes the logits returned by the model, extracts the argmax to obtain the label predictions for each token, and then translate the result into a list of string labels. \n",
    "\n",
    "label_sentence takes a list of input tokens and a predicate index, prepares the model input, call the model and then call decode_output to produce a final result. \n",
    "\n",
    "Note that you have already implemented all components necessary (preparing the input data from the token list and predicate index, decoding the model output). But now you are putting it together in one convenient function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "b72fc567",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = \"A U. N. team spent an hour inside the hospital , where it found evident signs of shelling and gunfire .\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "9026d718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_output(logits): # it will be useful to have this in a separate function later on\n",
    "    \"\"\"\n",
    "    Given the model output, return a list of string labels for each token. \n",
    "    \"\"\"\n",
    "    # Get predictions by taking argmax along the class dimension\n",
    "    predictions = torch.argmax(logits, dim=1)  # Shape will be [1, 128]\n",
    "    print(predictions)\n",
    "\n",
    "    tok_preds = []\n",
    "    for ix, n in enumerate(predictions.to('cpu').tolist()[0]):\n",
    "        tok_preds.append(id_to_role[n])\n",
    "\n",
    "    return tok_preds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "76f21f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentence(tokens, pred_idx):\n",
    "    \n",
    "    # complete this function to prepare token_ids, attention mask, predicate mask, then call the model. \n",
    "    # Decode the output to produce a list of labels. \n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "    bert_tokens = []\n",
    "    token_map = []  # Maps original tokens to BERT token positions\n",
    "    \n",
    "    for i, word in enumerate(tokens):\n",
    "        word_tokens = tokenizer.tokenize(word)\n",
    "        bert_tokens.extend(word_tokens)\n",
    "        token_map.extend([i] * len(word_tokens))\n",
    "        \n",
    "    # Truncate if needed\n",
    "    if len(bert_tokens) > 126:  # Reserve space for [CLS] and [SEP]\n",
    "        bert_tokens = bert_tokens[:126]\n",
    "        token_map = token_map[:126]\n",
    "    \n",
    "    # Add special tokens\n",
    "    bert_tokens = ['[CLS]'] + bert_tokens + ['[SEP]']\n",
    "    token_map = [-1] + token_map + [-1]  # -1 for special tokens\n",
    "    \n",
    "    input_ids = tokenizer.convert_tokens_to_ids(bert_tokens)\n",
    "    padding = [tokenizer.pad_token_id] * (128 - len(input_ids))\n",
    "    input_ids.extend(padding)\n",
    "    \n",
    "    attention_mask = [1] * len(bert_tokens) + [0] * (128 - len(bert_tokens))\n",
    "    \n",
    "    # Create predicate mask (token_type_ids)\n",
    "    pred_mask = [0] * 128\n",
    "    bert_pred_positions = [i for i, x in enumerate(token_map) if x == pred_idx]\n",
    "    if bert_pred_positions:\n",
    "        pred_mask[bert_pred_positions[0]] = 1  # Mark first subword of predicate\n",
    "    \n",
    "    # Convert to tensors and move to GPU\n",
    "    input_ids = torch.tensor([input_ids], dtype=torch.long).to(device)\n",
    "    attention_mask = torch.tensor([attention_mask], dtype=torch.long).to(device)\n",
    "    pred_mask = torch.tensor([pred_mask], dtype=torch.long).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attn_mask=attention_mask, pred_indicator=pred_mask)\n",
    "    \n",
    "    predictions = torch.argmax(outputs, dim=2)[0].cpu().numpy()\n",
    "    final_labels = []\n",
    "    \n",
    "    for i, token in enumerate(tokens):\n",
    "        # Find all BERT tokens corresponding to this original token\n",
    "        bert_indices = [j for j, x in enumerate(token_map) if x == i]\n",
    "        if not bert_indices:\n",
    "            final_labels.append(\"O\")\n",
    "            continue\n",
    "            \n",
    "        # Use the prediction of the first subword token\n",
    "        pred_id = predictions[bert_indices[0]]\n",
    "        if pred_id in id_to_role:\n",
    "            label = id_to_role[pred_id]\n",
    "            \n",
    "            # Handle continuation of B- labels\n",
    "            if (i > 0 and label.startswith('B-') and \n",
    "                len(final_labels) > 0 and  # Make sure we have previous labels\n",
    "                (final_labels[-1].startswith('B-') or final_labels[-1].startswith('I-')) and\n",
    "                final_labels[-1][2:] == label[2:]):  # Check if it's the same role type\n",
    "                    label = 'I-' + label[2:]\n",
    "            final_labels.append(label)\n",
    "        else:\n",
    "            final_labels.append(\"O\")\n",
    "    \n",
    "    return final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "98431b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: O\n",
      "U.: O\n",
      "N.: O\n",
      "team: O\n",
      "spent: O\n",
      "an: O\n",
      "hour: O\n",
      "inside: O\n",
      "the: B-ARGM-LOC\n",
      "hospital: I-ARGM-LOC\n",
      ",: O\n",
      "where: B-ARGM-LOC\n",
      "it: B-ARG0\n",
      "found: B-V\n",
      "evident: B-ARG1\n",
      "signs: I-ARG1\n",
      "of: I-ARG1\n",
      "shelling: I-ARG1\n",
      "and: I-ARG1\n",
      "gunfire: I-ARG1\n",
      ".: O\n"
     ]
    }
   ],
   "source": [
    "# Now you should be able to run\n",
    "\n",
    "label_test = label_sentence(tokens, 13) # Predicate is \"found\"\n",
    "for i,j in zip(tokens, label_test):\n",
    "    print(f'{i}: {j}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6c710b",
   "metadata": {},
   "source": [
    "The expected output is somethign like this: \n",
    "```   \n",
    " ('A', 'O'),\n",
    " ('U.', 'O'),\n",
    " ('N.', 'O'),\n",
    " ('team', 'O'),\n",
    " ('spent', 'O'),\n",
    " ('an', 'O'),\n",
    " ('hour', 'O'),\n",
    " ('inside', 'O'),\n",
    " ('the', 'B-ARGM-LOC'),\n",
    " ('hospital', 'I-ARGM-LOC'),\n",
    " (',', 'O'),\n",
    " ('where', 'B-ARGM-LOC'),\n",
    " ('it', 'B-ARG0'),\n",
    " ('found', 'B-V'),\n",
    " ('evident', 'B-ARG1'),\n",
    " ('signs', 'I-ARG1'),\n",
    " ('of', 'I-ARG1'),\n",
    " ('shelling', 'I-ARG1'),\n",
    " ('and', 'I-ARG1'),\n",
    " ('gunfire', 'I-ARG1'),\n",
    " ('.', 'O'),\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c0237e",
   "metadata": {},
   "source": [
    "### 5. Evaluation 1: Token-Based Accuracy\n",
    "We want to evaluate the model on the dev or test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "cc7aa897",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = SrlData(\"propbank_dev.tsv\") # Takes a while because we preprocess all data offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "dd62569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "loader = DataLoader(dev_data, batch_size = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcb3a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Load the model again if you stopped working prior to this step. \n",
    "# model = SrlModel()\n",
    "# model.load_state_dict(torch.load(\"srl_model_fulltrain_2epoch_finetune_1e-05.pt\"))\n",
    "# model = mode.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8ababd",
   "metadata": {},
   "source": [
    "**TODO**: Complete the evaluate_token_accuracy function below. The function should iterate through the items in the data loader (see training loop in part 3). Run the model on each sentence/predicate pair and extract the predictions.\n",
    "\n",
    "For each sentence, count the correct predictions and the total predictions. Finally, compute the accuracy as #correct_predictions / #total_predictions\n",
    "\n",
    "Careful: You need to filter out the padded positions ([PAD] target tokens), as well as [CLS] and [SEP]. It's okay to include [B-V] in the count though. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "fa091465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Accuracy: 0.9358\n",
      "Total correct predictions: 1299700\n",
      "Total valid tokens: 1388939\n",
      "0.9357502381314082\n"
     ]
    }
   ],
   "source": [
    "def evaluate_token_accuracy(model, loader):\n",
    "    \n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    total_correct = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation for efficiency\n",
    "        for batch in loader:\n",
    "            # Get batch data and move to GPU\n",
    "            ids = batch['ids'].squeeze(1).to('cuda')\n",
    "            mask = batch['mask'].squeeze(1).to('cuda')\n",
    "            targets = batch['targets'].squeeze(1).to('cuda')\n",
    "            pred_mask = batch['pred'].squeeze(1).to('cuda')\n",
    "            \n",
    "            # Get model predictions\n",
    "            outputs = model(input_ids=ids, attn_mask=mask, pred_indicator=pred_mask)\n",
    "            predictions = torch.argmax(outputs, dim=2)\n",
    "            \n",
    "            # Create mask for valid tokens (excluding [PAD], [CLS], [SEP])\n",
    "            valid_tokens = targets != -100  # -100 is the padding index\n",
    "            \n",
    "            # Count correct predictions\n",
    "            correct = (predictions == targets) & valid_tokens\n",
    "            total_correct += correct.sum().item()\n",
    "            total_predictions += valid_tokens.sum().item()\n",
    "    \n",
    "    accuracy = total_correct / total_predictions if total_predictions > 0 else 0\n",
    "    print(f\"Token Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Total correct predictions: {total_correct}\")\n",
    "    print(f\"Total valid tokens: {total_predictions}\")\n",
    "    \n",
    "    return accuracy\n",
    "dev_loader = DataLoader(dev_data, batch_size=32, shuffle=False)\n",
    "accuracy = evaluate_token_accuracy(model, dev_loader)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb27239",
   "metadata": {},
   "source": [
    "### 6. Span-Based evaluation \n",
    "\n",
    "While the accuracy score in part 5 is encouraging, an accuracy-based evaluation is problematic for two reasons. First, most of the target labels are actually O. Second, it only tells us that per-token prediction works, but does not directly evaluate the SRL performance. \n",
    "\n",
    "Instead, SRL systems are typically evaluated on micro-averaged precision, recall, and F1-score for predicting labeled spans. \n",
    "\n",
    "More specifically, for each sentence/predicate input, we run the model, decode the output, and extract a set of labeled spans (from the output and the target labels). These spans are (i,j,label) tuples.  \n",
    "\n",
    "We then compute the true_positives, false_positives, and false_negatives based on these spans. \n",
    "\n",
    "In the end, we can compute \n",
    "\n",
    "* Precision:  true_positive / (true_positives + false_positives)  , that is the number of correct spans out of all predicted spans. \n",
    "\n",
    "* Recall: true_positives / (true_positives + false_negatives) , that is the number of correct spans out of all target spans. \n",
    "\n",
    "* F1-score:   (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "\n",
    "For example, consider \n",
    "\n",
    "| |[CLS]|The|judge|scheduled|to|preside|over|his|trial|was|removed|from|the|case|today|.|             \n",
    "|--||---|-----|---------|--|-------|----|---|-----|---|-------|----|---|----|-----|-|             \n",
    "||0|1|2|3|4|5|6|7|8|9|1O|11|12|13|14|15|\n",
    "|target|[CLS]|B-ARG1|I-ARG1|B-V|B-ARG2|I-ARG2|I-ARG2|I-ARG2|I-ARG2|O|O|O|O|O|O|O|\n",
    "|prediction|[CLS]|B-ARG1|I-ARG1|B-V|I-ARG2|I-ARG2|O|O|O|O|O|O|O|O|B-ARGM-TMP|O|\n",
    "\n",
    "The target spans are (1,2,\"ARG1\"), and (4,8,\"ARG2\").\n",
    "\n",
    "The predicted spans would be (1,2,\"ARG1\"), (14,14,\"ARGM-TMP\"). Note that in the prediction, there is no proper ARG2 span because we are missing the B-ARG2 token, so this span should not be created. \n",
    "\n",
    "So for this sentence we woudl get: true_positives: 1 false_positives: 1 false_negatives: 1\n",
    "\n",
    "*TODO*: Complete the function evaluate_spans that performs the span-based evaluation on the given model and data loader. You can use the provided extract_spans function, which returns the spans as a dictionary. For example\n",
    "{(1,2): \"ARG1\", (4,8):\"ARG2\"} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379cfe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spans(labels):\n",
    "    spans = {} # map (start,end) ids to label\n",
    "    current_span_start = 0\n",
    "    current_span_type = \"\"\n",
    "    inside = False\n",
    "    for i, label in enumerate(labels):\n",
    "        if label.startswith(\"B\"):            \n",
    "            if inside: \n",
    "                if current_span_type != \"V\":\n",
    "                    spans[(current_span_start,i)] = current_span_type            \n",
    "            current_span_start = i\n",
    "            current_span_type = label[2:]\n",
    "            inside = True\n",
    "        elif inside and label.startswith(\"O\"):\n",
    "            if current_span_type != \"V\":\n",
    "                spans[(current_span_start,i)] = current_span_type\n",
    "            inside = False\n",
    "        elif inside and label.startswith(\"I\") and label[2:] != current_span_type:            \n",
    "            if current_span_type != \"V\":\n",
    "                spans[(current_span_start,i)] = current_span_type\n",
    "            inside = False\n",
    "    return spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "1a5486ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 0/43665\n",
      "Processing batch 100/43665\n",
      "Processing batch 200/43665\n",
      "Processing batch 300/43665\n",
      "Processing batch 400/43665\n",
      "Processing batch 500/43665\n",
      "Intermediate scores at batch 500:\n",
      "P: 0.8231 R: 0.8411 F1: 0.8320\n",
      "Processing batch 600/43665\n",
      "Processing batch 700/43665\n",
      "Processing batch 800/43665\n",
      "Processing batch 900/43665\n",
      "Processing batch 1000/43665\n",
      "Intermediate scores at batch 1000:\n",
      "P: 0.8108 R: 0.8366 F1: 0.8235\n",
      "Processing batch 1100/43665\n",
      "Processing batch 1200/43665\n",
      "Processing batch 1300/43665\n",
      "Processing batch 1400/43665\n",
      "Processing batch 1500/43665\n",
      "Intermediate scores at batch 1500:\n",
      "P: 0.8049 R: 0.8289 F1: 0.8167\n",
      "Processing batch 1600/43665\n",
      "Processing batch 1700/43665\n",
      "Processing batch 1800/43665\n",
      "Processing batch 1900/43665\n",
      "Processing batch 2000/43665\n",
      "Intermediate scores at batch 2000:\n",
      "P: 0.7948 R: 0.8250 F1: 0.8096\n",
      "Processing batch 2100/43665\n",
      "Processing batch 2200/43665\n",
      "Processing batch 2300/43665\n",
      "Processing batch 2400/43665\n",
      "Processing batch 2500/43665\n",
      "Intermediate scores at batch 2500:\n",
      "P: 0.7924 R: 0.8208 F1: 0.8063\n",
      "Processing batch 2600/43665\n",
      "Processing batch 2700/43665\n",
      "Processing batch 2800/43665\n",
      "Processing batch 2900/43665\n",
      "Processing batch 3000/43665\n",
      "Intermediate scores at batch 3000:\n",
      "P: 0.7911 R: 0.8202 F1: 0.8054\n",
      "Processing batch 3100/43665\n",
      "Processing batch 3200/43665\n",
      "Processing batch 3300/43665\n",
      "Processing batch 3400/43665\n",
      "Processing batch 3500/43665\n",
      "Intermediate scores at batch 3500:\n",
      "P: 0.7932 R: 0.8215 F1: 0.8071\n",
      "Processing batch 3600/43665\n",
      "Processing batch 3700/43665\n",
      "Processing batch 3800/43665\n",
      "Processing batch 3900/43665\n",
      "Processing batch 4000/43665\n",
      "Intermediate scores at batch 4000:\n",
      "P: 0.7898 R: 0.8194 F1: 0.8043\n",
      "Processing batch 4100/43665\n",
      "Processing batch 4200/43665\n",
      "Processing batch 4300/43665\n",
      "Processing batch 4400/43665\n",
      "Processing batch 4500/43665\n",
      "Intermediate scores at batch 4500:\n",
      "P: 0.7872 R: 0.8195 F1: 0.8030\n",
      "Processing batch 4600/43665\n",
      "Processing batch 4700/43665\n",
      "Processing batch 4800/43665\n",
      "Processing batch 4900/43665\n",
      "Processing batch 5000/43665\n",
      "Intermediate scores at batch 5000:\n",
      "P: 0.7882 R: 0.8200 F1: 0.8038\n",
      "Processing batch 5100/43665\n",
      "Processing batch 5200/43665\n",
      "Processing batch 5300/43665\n",
      "Processing batch 5400/43665\n",
      "Processing batch 5500/43665\n",
      "Intermediate scores at batch 5500:\n",
      "P: 0.7918 R: 0.8237 F1: 0.8074\n",
      "Processing batch 5600/43665\n",
      "Processing batch 5700/43665\n",
      "Processing batch 5800/43665\n",
      "Processing batch 5900/43665\n",
      "Processing batch 6000/43665\n",
      "Intermediate scores at batch 6000:\n",
      "P: 0.7928 R: 0.8234 F1: 0.8078\n",
      "Processing batch 6100/43665\n",
      "Processing batch 6200/43665\n",
      "Processing batch 6300/43665\n",
      "Processing batch 6400/43665\n",
      "Processing batch 6500/43665\n",
      "Intermediate scores at batch 6500:\n",
      "P: 0.7923 R: 0.8214 F1: 0.8066\n",
      "Processing batch 6600/43665\n",
      "Processing batch 6700/43665\n",
      "Processing batch 6800/43665\n",
      "Processing batch 6900/43665\n",
      "Processing batch 7000/43665\n",
      "Intermediate scores at batch 7000:\n",
      "P: 0.7921 R: 0.8204 F1: 0.8060\n",
      "Processing batch 7100/43665\n",
      "Processing batch 7200/43665\n",
      "Processing batch 7300/43665\n",
      "Processing batch 7400/43665\n",
      "Processing batch 7500/43665\n",
      "Intermediate scores at batch 7500:\n",
      "P: 0.7914 R: 0.8187 F1: 0.8048\n",
      "Processing batch 7600/43665\n",
      "Processing batch 7700/43665\n",
      "Processing batch 7800/43665\n",
      "Processing batch 7900/43665\n",
      "Processing batch 8000/43665\n",
      "Intermediate scores at batch 8000:\n",
      "P: 0.7918 R: 0.8177 F1: 0.8045\n",
      "Processing batch 8100/43665\n",
      "Processing batch 8200/43665\n",
      "Processing batch 8300/43665\n",
      "Processing batch 8400/43665\n",
      "Processing batch 8500/43665\n",
      "Intermediate scores at batch 8500:\n",
      "P: 0.7935 R: 0.8191 F1: 0.8061\n",
      "Processing batch 8600/43665\n",
      "Processing batch 8700/43665\n",
      "Processing batch 8800/43665\n",
      "Processing batch 8900/43665\n",
      "Processing batch 9000/43665\n",
      "Intermediate scores at batch 9000:\n",
      "P: 0.7940 R: 0.8190 F1: 0.8063\n",
      "Processing batch 9100/43665\n",
      "Processing batch 9200/43665\n",
      "Processing batch 9300/43665\n",
      "Processing batch 9400/43665\n",
      "Processing batch 9500/43665\n",
      "Intermediate scores at batch 9500:\n",
      "P: 0.7949 R: 0.8196 F1: 0.8071\n",
      "Processing batch 9600/43665\n",
      "Processing batch 9700/43665\n",
      "Processing batch 9800/43665\n",
      "Processing batch 9900/43665\n",
      "Processing batch 10000/43665\n",
      "Intermediate scores at batch 10000:\n",
      "P: 0.7965 R: 0.8209 F1: 0.8085\n",
      "Processing batch 10100/43665\n",
      "Processing batch 10200/43665\n",
      "Processing batch 10300/43665\n",
      "Processing batch 10400/43665\n",
      "Processing batch 10500/43665\n",
      "Intermediate scores at batch 10500:\n",
      "P: 0.7967 R: 0.8198 F1: 0.8081\n",
      "Processing batch 10600/43665\n",
      "Processing batch 10700/43665\n",
      "Processing batch 10800/43665\n",
      "Processing batch 10900/43665\n",
      "Processing batch 11000/43665\n",
      "Intermediate scores at batch 11000:\n",
      "P: 0.7971 R: 0.8200 F1: 0.8084\n",
      "Processing batch 11100/43665\n",
      "Processing batch 11200/43665\n",
      "Processing batch 11300/43665\n",
      "Processing batch 11400/43665\n",
      "Processing batch 11500/43665\n",
      "Intermediate scores at batch 11500:\n",
      "P: 0.7946 R: 0.8175 F1: 0.8059\n",
      "Processing batch 11600/43665\n",
      "Processing batch 11700/43665\n",
      "Processing batch 11800/43665\n",
      "Processing batch 11900/43665\n",
      "Processing batch 12000/43665\n",
      "Intermediate scores at batch 12000:\n",
      "P: 0.7938 R: 0.8165 F1: 0.8050\n",
      "Processing batch 12100/43665\n",
      "Processing batch 12200/43665\n",
      "Processing batch 12300/43665\n",
      "Processing batch 12400/43665\n",
      "Processing batch 12500/43665\n",
      "Intermediate scores at batch 12500:\n",
      "P: 0.7932 R: 0.8160 F1: 0.8044\n",
      "Processing batch 12600/43665\n",
      "Processing batch 12700/43665\n",
      "Processing batch 12800/43665\n",
      "Processing batch 12900/43665\n",
      "Processing batch 13000/43665\n",
      "Intermediate scores at batch 13000:\n",
      "P: 0.7930 R: 0.8153 F1: 0.8040\n",
      "Processing batch 13100/43665\n",
      "Processing batch 13200/43665\n",
      "Processing batch 13300/43665\n",
      "Processing batch 13400/43665\n",
      "Processing batch 13500/43665\n",
      "Intermediate scores at batch 13500:\n",
      "P: 0.7941 R: 0.8165 F1: 0.8051\n",
      "Processing batch 13600/43665\n",
      "Processing batch 13700/43665\n",
      "Processing batch 13800/43665\n",
      "Processing batch 13900/43665\n",
      "Processing batch 14000/43665\n",
      "Intermediate scores at batch 14000:\n",
      "P: 0.7951 R: 0.8168 F1: 0.8058\n",
      "Processing batch 14100/43665\n",
      "Processing batch 14200/43665\n",
      "Processing batch 14300/43665\n",
      "Processing batch 14400/43665\n",
      "Processing batch 14500/43665\n",
      "Intermediate scores at batch 14500:\n",
      "P: 0.7956 R: 0.8164 F1: 0.8059\n",
      "Processing batch 14600/43665\n",
      "Processing batch 14700/43665\n",
      "Processing batch 14800/43665\n",
      "Processing batch 14900/43665\n",
      "Processing batch 15000/43665\n",
      "Intermediate scores at batch 15000:\n",
      "P: 0.7970 R: 0.8174 F1: 0.8071\n",
      "Processing batch 15100/43665\n",
      "Processing batch 15200/43665\n",
      "Processing batch 15300/43665\n",
      "Processing batch 15400/43665\n",
      "Processing batch 15500/43665\n",
      "Intermediate scores at batch 15500:\n",
      "P: 0.7983 R: 0.8183 F1: 0.8082\n",
      "Processing batch 15600/43665\n",
      "Processing batch 15700/43665\n",
      "Processing batch 15800/43665\n",
      "Processing batch 15900/43665\n",
      "Processing batch 16000/43665\n",
      "Intermediate scores at batch 16000:\n",
      "P: 0.7990 R: 0.8186 F1: 0.8086\n",
      "Processing batch 16100/43665\n",
      "Processing batch 16200/43665\n",
      "Processing batch 16300/43665\n",
      "Processing batch 16400/43665\n",
      "Processing batch 16500/43665\n",
      "Intermediate scores at batch 16500:\n",
      "P: 0.7998 R: 0.8189 F1: 0.8092\n",
      "Processing batch 16600/43665\n",
      "Processing batch 16700/43665\n",
      "Processing batch 16800/43665\n",
      "Processing batch 16900/43665\n",
      "Processing batch 17000/43665\n",
      "Intermediate scores at batch 17000:\n",
      "P: 0.8006 R: 0.8196 F1: 0.8100\n",
      "Processing batch 17100/43665\n",
      "Processing batch 17200/43665\n",
      "Processing batch 17300/43665\n",
      "Processing batch 17400/43665\n",
      "Processing batch 17500/43665\n",
      "Intermediate scores at batch 17500:\n",
      "P: 0.8013 R: 0.8196 F1: 0.8104\n",
      "Processing batch 17600/43665\n",
      "Processing batch 17700/43665\n",
      "Processing batch 17800/43665\n",
      "Processing batch 17900/43665\n",
      "Processing batch 18000/43665\n",
      "Intermediate scores at batch 18000:\n",
      "P: 0.8017 R: 0.8198 F1: 0.8107\n",
      "Processing batch 18100/43665\n",
      "Processing batch 18200/43665\n",
      "Processing batch 18300/43665\n",
      "Processing batch 18400/43665\n",
      "Processing batch 18500/43665\n",
      "Intermediate scores at batch 18500:\n",
      "P: 0.8017 R: 0.8198 F1: 0.8106\n",
      "Processing batch 18600/43665\n",
      "Processing batch 18700/43665\n",
      "Processing batch 18800/43665\n",
      "Processing batch 18900/43665\n",
      "Processing batch 19000/43665\n",
      "Intermediate scores at batch 19000:\n",
      "P: 0.8014 R: 0.8189 F1: 0.8100\n",
      "Processing batch 19100/43665\n",
      "Processing batch 19200/43665\n",
      "Processing batch 19300/43665\n",
      "Processing batch 19400/43665\n",
      "Processing batch 19500/43665\n",
      "Intermediate scores at batch 19500:\n",
      "P: 0.8022 R: 0.8192 F1: 0.8106\n",
      "Processing batch 19600/43665\n",
      "Processing batch 19700/43665\n",
      "Processing batch 19800/43665\n",
      "Processing batch 19900/43665\n",
      "Processing batch 20000/43665\n",
      "Intermediate scores at batch 20000:\n",
      "P: 0.8031 R: 0.8192 F1: 0.8111\n",
      "Processing batch 20100/43665\n",
      "Processing batch 20200/43665\n",
      "Processing batch 20300/43665\n",
      "Processing batch 20400/43665\n",
      "Processing batch 20500/43665\n",
      "Intermediate scores at batch 20500:\n",
      "P: 0.8037 R: 0.8198 F1: 0.8117\n",
      "Processing batch 20600/43665\n",
      "Processing batch 20700/43665\n",
      "Processing batch 20800/43665\n",
      "Processing batch 20900/43665\n",
      "Processing batch 21000/43665\n",
      "Intermediate scores at batch 21000:\n",
      "P: 0.8045 R: 0.8205 F1: 0.8124\n",
      "Processing batch 21100/43665\n",
      "Processing batch 21200/43665\n",
      "Processing batch 21300/43665\n",
      "Processing batch 21400/43665\n",
      "Processing batch 21500/43665\n",
      "Intermediate scores at batch 21500:\n",
      "P: 0.8047 R: 0.8208 F1: 0.8127\n",
      "Processing batch 21600/43665\n",
      "Processing batch 21700/43665\n",
      "Processing batch 21800/43665\n",
      "Processing batch 21900/43665\n",
      "Processing batch 22000/43665\n",
      "Intermediate scores at batch 22000:\n",
      "P: 0.8051 R: 0.8207 F1: 0.8128\n",
      "Processing batch 22100/43665\n",
      "Processing batch 22200/43665\n",
      "Processing batch 22300/43665\n",
      "Processing batch 22400/43665\n",
      "Processing batch 22500/43665\n",
      "Intermediate scores at batch 22500:\n",
      "P: 0.8060 R: 0.8215 F1: 0.8137\n",
      "Processing batch 22600/43665\n",
      "Processing batch 22700/43665\n",
      "Processing batch 22800/43665\n",
      "Processing batch 22900/43665\n",
      "Processing batch 23000/43665\n",
      "Intermediate scores at batch 23000:\n",
      "P: 0.8064 R: 0.8216 F1: 0.8139\n",
      "Processing batch 23100/43665\n",
      "Processing batch 23200/43665\n",
      "Processing batch 23300/43665\n",
      "Processing batch 23400/43665\n",
      "Processing batch 23500/43665\n",
      "Intermediate scores at batch 23500:\n",
      "P: 0.8066 R: 0.8214 F1: 0.8139\n",
      "Processing batch 23600/43665\n",
      "Processing batch 23700/43665\n",
      "Processing batch 23800/43665\n",
      "Processing batch 23900/43665\n",
      "Processing batch 24000/43665\n",
      "Intermediate scores at batch 24000:\n",
      "P: 0.8074 R: 0.8222 F1: 0.8147\n",
      "Processing batch 24100/43665\n",
      "Processing batch 24200/43665\n",
      "Processing batch 24300/43665\n",
      "Processing batch 24400/43665\n",
      "Processing batch 24500/43665\n",
      "Intermediate scores at batch 24500:\n",
      "P: 0.8076 R: 0.8225 F1: 0.8150\n",
      "Processing batch 24600/43665\n",
      "Processing batch 24700/43665\n",
      "Processing batch 24800/43665\n",
      "Processing batch 24900/43665\n",
      "Processing batch 25000/43665\n",
      "Intermediate scores at batch 25000:\n",
      "P: 0.8072 R: 0.8224 F1: 0.8147\n",
      "Processing batch 25100/43665\n",
      "Processing batch 25200/43665\n",
      "Processing batch 25300/43665\n",
      "Processing batch 25400/43665\n",
      "Processing batch 25500/43665\n",
      "Intermediate scores at batch 25500:\n",
      "P: 0.8074 R: 0.8223 F1: 0.8148\n",
      "Processing batch 25600/43665\n",
      "Processing batch 25700/43665\n",
      "Processing batch 25800/43665\n",
      "Processing batch 25900/43665\n",
      "Processing batch 26000/43665\n",
      "Intermediate scores at batch 26000:\n",
      "P: 0.8071 R: 0.8221 F1: 0.8145\n",
      "Processing batch 26100/43665\n",
      "Processing batch 26200/43665\n",
      "Processing batch 26300/43665\n",
      "Processing batch 26400/43665\n",
      "Processing batch 26500/43665\n",
      "Intermediate scores at batch 26500:\n",
      "P: 0.8072 R: 0.8220 F1: 0.8145\n",
      "Processing batch 26600/43665\n",
      "Processing batch 26700/43665\n",
      "Processing batch 26800/43665\n",
      "Processing batch 26900/43665\n",
      "Processing batch 27000/43665\n",
      "Intermediate scores at batch 27000:\n",
      "P: 0.8073 R: 0.8221 F1: 0.8147\n",
      "Processing batch 27100/43665\n",
      "Processing batch 27200/43665\n",
      "Processing batch 27300/43665\n",
      "Processing batch 27400/43665\n",
      "Processing batch 27500/43665\n",
      "Intermediate scores at batch 27500:\n",
      "P: 0.8074 R: 0.8223 F1: 0.8148\n",
      "Processing batch 27600/43665\n",
      "Processing batch 27700/43665\n",
      "Processing batch 27800/43665\n",
      "Processing batch 27900/43665\n",
      "Processing batch 28000/43665\n",
      "Intermediate scores at batch 28000:\n",
      "P: 0.8067 R: 0.8217 F1: 0.8141\n",
      "Processing batch 28100/43665\n",
      "Processing batch 28200/43665\n",
      "Processing batch 28300/43665\n",
      "Processing batch 28400/43665\n",
      "Processing batch 28500/43665\n",
      "Intermediate scores at batch 28500:\n",
      "P: 0.8057 R: 0.8206 F1: 0.8131\n",
      "Processing batch 28600/43665\n",
      "Processing batch 28700/43665\n",
      "Processing batch 28800/43665\n",
      "Processing batch 28900/43665\n",
      "Processing batch 29000/43665\n",
      "Intermediate scores at batch 29000:\n",
      "P: 0.8057 R: 0.8207 F1: 0.8131\n",
      "Processing batch 29100/43665\n",
      "Processing batch 29200/43665\n",
      "Processing batch 29300/43665\n",
      "Processing batch 29400/43665\n",
      "Processing batch 29500/43665\n",
      "Intermediate scores at batch 29500:\n",
      "P: 0.8057 R: 0.8206 F1: 0.8131\n",
      "Processing batch 29600/43665\n",
      "Processing batch 29700/43665\n",
      "Processing batch 29800/43665\n",
      "Processing batch 29900/43665\n",
      "Processing batch 30000/43665\n",
      "Intermediate scores at batch 30000:\n",
      "P: 0.8054 R: 0.8204 F1: 0.8128\n",
      "Processing batch 30100/43665\n",
      "Processing batch 30200/43665\n",
      "Processing batch 30300/43665\n",
      "Processing batch 30400/43665\n",
      "Processing batch 30500/43665\n",
      "Intermediate scores at batch 30500:\n",
      "P: 0.8044 R: 0.8193 F1: 0.8118\n",
      "Processing batch 30600/43665\n",
      "Processing batch 30700/43665\n",
      "Processing batch 30800/43665\n",
      "Processing batch 30900/43665\n",
      "Processing batch 31000/43665\n",
      "Intermediate scores at batch 31000:\n",
      "P: 0.8044 R: 0.8192 F1: 0.8117\n",
      "Processing batch 31100/43665\n",
      "Processing batch 31200/43665\n",
      "Processing batch 31300/43665\n",
      "Processing batch 31400/43665\n",
      "Processing batch 31500/43665\n",
      "Intermediate scores at batch 31500:\n",
      "P: 0.8048 R: 0.8197 F1: 0.8122\n",
      "Processing batch 31600/43665\n",
      "Processing batch 31700/43665\n",
      "Processing batch 31800/43665\n",
      "Processing batch 31900/43665\n",
      "Processing batch 32000/43665\n",
      "Intermediate scores at batch 32000:\n",
      "P: 0.8048 R: 0.8194 F1: 0.8120\n",
      "Processing batch 32100/43665\n",
      "Processing batch 32200/43665\n",
      "Processing batch 32300/43665\n",
      "Processing batch 32400/43665\n",
      "Processing batch 32500/43665\n",
      "Intermediate scores at batch 32500:\n",
      "P: 0.8045 R: 0.8189 F1: 0.8116\n",
      "Processing batch 32600/43665\n",
      "Processing batch 32700/43665\n",
      "Processing batch 32800/43665\n",
      "Processing batch 32900/43665\n",
      "Processing batch 33000/43665\n",
      "Intermediate scores at batch 33000:\n",
      "P: 0.8043 R: 0.8188 F1: 0.8115\n",
      "Processing batch 33100/43665\n",
      "Processing batch 33200/43665\n",
      "Processing batch 33300/43665\n",
      "Processing batch 33400/43665\n",
      "Processing batch 33500/43665\n",
      "Intermediate scores at batch 33500:\n",
      "P: 0.8041 R: 0.8186 F1: 0.8113\n",
      "Processing batch 33600/43665\n",
      "Processing batch 33700/43665\n",
      "Processing batch 33800/43665\n",
      "Processing batch 33900/43665\n",
      "Processing batch 34000/43665\n",
      "Intermediate scores at batch 34000:\n",
      "P: 0.8060 R: 0.8204 F1: 0.8131\n",
      "Processing batch 34100/43665\n",
      "Processing batch 34200/43665\n",
      "Processing batch 34300/43665\n",
      "Processing batch 34400/43665\n",
      "Processing batch 34500/43665\n",
      "Intermediate scores at batch 34500:\n",
      "P: 0.8078 R: 0.8221 F1: 0.8149\n",
      "Processing batch 34600/43665\n",
      "Processing batch 34700/43665\n",
      "Processing batch 34800/43665\n",
      "Processing batch 34900/43665\n",
      "Processing batch 35000/43665\n",
      "Intermediate scores at batch 35000:\n",
      "P: 0.8096 R: 0.8238 F1: 0.8167\n",
      "Processing batch 35100/43665\n",
      "Processing batch 35200/43665\n",
      "Processing batch 35300/43665\n",
      "Processing batch 35400/43665\n",
      "Processing batch 35500/43665\n",
      "Intermediate scores at batch 35500:\n",
      "P: 0.8112 R: 0.8253 F1: 0.8182\n",
      "Processing batch 35600/43665\n",
      "Processing batch 35700/43665\n",
      "Processing batch 35800/43665\n",
      "Processing batch 35900/43665\n",
      "Processing batch 36000/43665\n",
      "Intermediate scores at batch 36000:\n",
      "P: 0.8124 R: 0.8262 F1: 0.8192\n",
      "Processing batch 36100/43665\n",
      "Processing batch 36200/43665\n",
      "Processing batch 36300/43665\n",
      "Processing batch 36400/43665\n",
      "Processing batch 36500/43665\n",
      "Intermediate scores at batch 36500:\n",
      "P: 0.8138 R: 0.8274 F1: 0.8205\n",
      "Processing batch 36600/43665\n",
      "Processing batch 36700/43665\n",
      "Processing batch 36800/43665\n",
      "Processing batch 36900/43665\n",
      "Processing batch 37000/43665\n",
      "Intermediate scores at batch 37000:\n",
      "P: 0.8118 R: 0.8281 F1: 0.8199\n",
      "Processing batch 37100/43665\n",
      "Processing batch 37200/43665\n",
      "Processing batch 37300/43665\n",
      "Processing batch 37400/43665\n",
      "Processing batch 37500/43665\n",
      "Intermediate scores at batch 37500:\n",
      "P: 0.8125 R: 0.8289 F1: 0.8206\n",
      "Processing batch 37600/43665\n",
      "Processing batch 37700/43665\n",
      "Processing batch 37800/43665\n",
      "Processing batch 37900/43665\n",
      "Processing batch 38000/43665\n",
      "Intermediate scores at batch 38000:\n",
      "P: 0.8127 R: 0.8296 F1: 0.8210\n",
      "Processing batch 38100/43665\n",
      "Processing batch 38200/43665\n",
      "Processing batch 38300/43665\n",
      "Processing batch 38400/43665\n",
      "Processing batch 38500/43665\n",
      "Intermediate scores at batch 38500:\n",
      "P: 0.8123 R: 0.8294 F1: 0.8208\n",
      "Processing batch 38600/43665\n",
      "Processing batch 38700/43665\n",
      "Processing batch 38800/43665\n",
      "Processing batch 38900/43665\n",
      "Processing batch 39000/43665\n",
      "Intermediate scores at batch 39000:\n",
      "P: 0.8121 R: 0.8296 F1: 0.8208\n",
      "Processing batch 39100/43665\n",
      "Processing batch 39200/43665\n",
      "Processing batch 39300/43665\n",
      "Processing batch 39400/43665\n",
      "Processing batch 39500/43665\n",
      "Intermediate scores at batch 39500:\n",
      "P: 0.8121 R: 0.8297 F1: 0.8208\n",
      "Processing batch 39600/43665\n",
      "Processing batch 39700/43665\n",
      "Processing batch 39800/43665\n",
      "Processing batch 39900/43665\n",
      "Processing batch 40000/43665\n",
      "Intermediate scores at batch 40000:\n",
      "P: 0.8119 R: 0.8293 F1: 0.8205\n",
      "Processing batch 40100/43665\n",
      "Processing batch 40200/43665\n",
      "Processing batch 40300/43665\n",
      "Processing batch 40400/43665\n",
      "Processing batch 40500/43665\n",
      "Intermediate scores at batch 40500:\n",
      "P: 0.8122 R: 0.8288 F1: 0.8204\n",
      "Processing batch 40600/43665\n",
      "Processing batch 40700/43665\n",
      "Processing batch 40800/43665\n",
      "Processing batch 40900/43665\n",
      "Processing batch 41000/43665\n",
      "Intermediate scores at batch 41000:\n",
      "P: 0.8110 R: 0.8291 F1: 0.8199\n",
      "Processing batch 41100/43665\n",
      "Processing batch 41200/43665\n",
      "Processing batch 41300/43665\n",
      "Processing batch 41400/43665\n",
      "Processing batch 41500/43665\n",
      "Intermediate scores at batch 41500:\n",
      "P: 0.8109 R: 0.8291 F1: 0.8199\n",
      "Processing batch 41600/43665\n",
      "Processing batch 41700/43665\n",
      "Processing batch 41800/43665\n",
      "Processing batch 41900/43665\n",
      "Processing batch 42000/43665\n",
      "Intermediate scores at batch 42000:\n",
      "P: 0.8106 R: 0.8289 F1: 0.8197\n",
      "Processing batch 42100/43665\n",
      "Processing batch 42200/43665\n",
      "Processing batch 42300/43665\n",
      "Processing batch 42400/43665\n",
      "Processing batch 42500/43665\n",
      "Intermediate scores at batch 42500:\n",
      "P: 0.8102 R: 0.8286 F1: 0.8193\n",
      "Processing batch 42600/43665\n",
      "Processing batch 42700/43665\n",
      "Processing batch 42800/43665\n",
      "Processing batch 42900/43665\n",
      "Processing batch 43000/43665\n",
      "Intermediate scores at batch 43000:\n",
      "P: 0.8103 R: 0.8287 F1: 0.8194\n",
      "Processing batch 43100/43665\n",
      "Processing batch 43200/43665\n",
      "Processing batch 43300/43665\n",
      "Processing batch 43400/43665\n",
      "Processing batch 43500/43665\n",
      "Intermediate scores at batch 43500:\n",
      "P: 0.8092 R: 0.8284 F1: 0.8187\n",
      "Processing batch 43600/43665\n",
      "\n",
      "Final Results:\n",
      "True Positives: 73628\n",
      "False Positives: 17430\n",
      "False Negatives: 15253\n",
      "Precision: 0.8086\n",
      "Recall: 0.8284\n",
      "F1: 0.8184\n",
      "(0.8085835401611271, 0.8283885194810108, 0.8183662191099224)\n"
     ]
    }
   ],
   "source": [
    "def evaluate_spans(model, loader):\n",
    "    \"\"\"\n",
    "    Span-based evaluation that properly handles padding tokens.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    total_tp = 0\n",
    "    total_fp = 0\n",
    "    total_fn = 0\n",
    "    \n",
    "    total_batches = len(loader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(loader):\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f\"Processing batch {batch_idx}/{total_batches}\")\n",
    "                \n",
    "            # Process batch\n",
    "            ids = batch['ids'].squeeze(1).to('cuda')\n",
    "            mask = batch['mask'].squeeze(1).to('cuda')\n",
    "            targets = batch['targets'].squeeze(1).to('cuda')\n",
    "            pred_mask = batch['pred'].squeeze(1).to('cuda')\n",
    "            \n",
    "            # Get predictions\n",
    "            outputs = model(ids, mask, pred_mask)\n",
    "            predictions = torch.argmax(outputs, dim=2)\n",
    "            \n",
    "            # Process each sequence in batch\n",
    "            for i in range(predictions.size(0)):\n",
    "                pred_seq = predictions[i]\n",
    "                target_seq = targets[i]\n",
    "                attention_mask = mask[i]\n",
    "                \n",
    "                # Convert to labels, ignoring padding tokens\n",
    "                pred_labels = []\n",
    "                target_labels = []\n",
    "                \n",
    "                # Only process tokens where attention_mask is 1 (non-padding)\n",
    "                for j in range(len(pred_seq)):\n",
    "                    if attention_mask[j] == 1:  # This is a real token\n",
    "                        pred_id = pred_seq[j].item()\n",
    "                        target_id = target_seq[j].item()\n",
    "                        \n",
    "                        # Only include if target is not padding (-100)\n",
    "                        if target_id != -100:\n",
    "                            pred_labels.append(id_to_role[pred_id])\n",
    "                            target_labels.append(id_to_role[target_id])\n",
    "                \n",
    "                # Extract spans for valid tokens\n",
    "                pred_spans = extract_spans(pred_labels)\n",
    "                target_spans = extract_spans(target_labels)\n",
    "                \n",
    "                # Calculate metrics\n",
    "                for span, label in pred_spans.items():\n",
    "                    if span in target_spans and target_spans[span] == label:\n",
    "                        total_tp += 1\n",
    "                    else:\n",
    "                        total_fp += 1\n",
    "                \n",
    "                for span, label in target_spans.items():\n",
    "                    if span not in pred_spans or pred_spans[span] != label:\n",
    "                        total_fn += 1\n",
    "            \n",
    "            # Print intermediate results every 500 batches\n",
    "            if batch_idx % 500 == 0 and batch_idx > 0:\n",
    "                curr_p = total_tp / (total_tp + total_fp + 1e-8)\n",
    "                curr_r = total_tp / (total_tp + total_fn + 1e-8)\n",
    "                curr_f = 2 * curr_p * curr_r / (curr_p + curr_r + 1e-8)\n",
    "                print(f\"Intermediate scores at batch {batch_idx}:\")\n",
    "                print(f\"P: {curr_p:.4f} R: {curr_r:.4f} F1: {curr_f:.4f}\")\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    final_p = total_tp / (total_tp + total_fp + 1e-8)\n",
    "    final_r = total_tp / (total_tp + total_fn + 1e-8)\n",
    "    final_f = 2 * final_p * final_r / (final_p + final_r + 1e-8)\n",
    "    \n",
    "    print(\"\\nFinal Results:\")\n",
    "    print(f\"True Positives: {total_tp}\")\n",
    "    print(f\"False Positives: {total_fp}\")\n",
    "    print(f\"False Negatives: {total_fn}\")\n",
    "    print(f\"Precision: {final_p:.4f}\")\n",
    "    print(f\"Recall: {final_r:.4f}\")\n",
    "    print(f\"F1: {final_f:.4f}\")\n",
    "    \n",
    "    return final_p, final_r, final_f\n",
    "print(evaluate_spans(model, loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e35d04",
   "metadata": {},
   "source": [
    "In my evaluation, I got an F score of 0.82  (which slightly below the state-of-the art in 2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd94c3a2",
   "metadata": {},
   "source": [
    "### OPTIONAL: \n",
    "\n",
    "Repeat the span-based evaluation, but print out precision/recall/f1-score for each role separately."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
